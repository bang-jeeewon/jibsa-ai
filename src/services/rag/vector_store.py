# from langchain_openai import OpenAIEmbeddings
# from langchain_google_genai import GoogleGenerativeAIEmbeddings
# from langchain_huggingface import HuggingFaceEmbeddings
# from langchain_chroma import Chroma
from src.config.config import OPENAI_API_KEY, GOOGLE_API_KEY, RENDER
import time
import random
import gc

class VectorStoreService:
    def __init__(self, persist_directory=None, embedding_model="openai"):
        """
        VectorStoreService ì´ˆê¸°í™”
        :param persist_directory: Noneì´ë©´ in-memory ëª¨ë“œ (íŒŒì¼ ì €ì¥ ì•ˆ í•¨)
        :param embedding_model: ì‚¬ìš©í•  ì„ë² ë”© ëª¨ë¸ ("openai" ë˜ëŠ” "gemini")
        """
        # from langchain_openai import OpenAIEmbeddings
        # from langchain_google_genai import GoogleGenerativeAIEmbeddings
        # from langchain_chroma import Chroma

        self.persist_directory = persist_directory
        gc.collect()
        print("VectorStoreService 1")

        # 1. ì„ë² ë”© ë¼ì´ë¸ŒëŸ¬ë¦¬ë§Œ ë¨¼ì € ë¡œë“œ
        if embedding_model == "gemini":
            from langchain_google_genai import GoogleGenerativeAIEmbeddings
            gc.collect()
            print("VectorStoreService 2")
            self.embeddings = GoogleGenerativeAIEmbeddings(
                model="models/gemini-embedding-001",
                google_api_key=GOOGLE_API_KEY,  # API í‚¤ ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬
                # rate limit ë°©ì§€ë¥¼ ìœ„í•œ ì¶”ê°€ ì„¤ì •
                request_options={"timeout": 60}  # íƒ€ì„ì•„ì›ƒ ì„¤ì •
            )
        else:
            from langchain_openai import OpenAIEmbeddings
            gc.collect()
            print("VectorStoreService 2.1")
            self.embeddings = OpenAIEmbeddings(
                model="text-embedding-3-small",
                api_key=OPENAI_API_KEY
            )
        gc.collect() # 2. ì„ì‹œ ë©”ëª¨ë¦¬ ì²­ì†Œ  
        
        # 3. ê·¸ ë‹¤ìŒ Chroma ë¡œë“œ
        from langchain_chroma import Chroma
        gc.collect()
        print("VectorStoreService 3")
        self.vector_db = Chroma(
            persist_directory=self.persist_directory,  # Noneì´ë©´ ë©”ëª¨ë¦¬ë§Œ ì‚¬ìš©
            embedding_function=self.embeddings,
            collection_name="apt_notices" # ì»¬ë ‰ì…˜ ì´ë¦„ ì§€ì •
        )
        gc.collect() # 4. ë©”ëª¨ë¦¬ ì²­ì†Œ  
        
        # # ì„ë² ë”© ëª¨ë¸ ì„ íƒ (ê¸°ë³¸ê°’: OpenAI - ë” ì•ˆì •ì ì´ê³  rate limitì´ ë†’ìŒ)
        # if embedding_model == "gemini":
        #     # GoogleGenerativeAIEmbeddingsì— ì¬ì‹œë„ ë¡œì§ì´ ë‚´ì¥ë˜ì–´ ìˆì§€ë§Œ, ì¶”ê°€ ì„¤ì • ê°€ëŠ¥
        #     self.embeddings = GoogleGenerativeAIEmbeddings(
        #         model="models/gemini-embedding-001",
        #         google_api_key=GOOGLE_API_KEY,  # API í‚¤ ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬
        #         # rate limit ë°©ì§€ë¥¼ ìœ„í•œ ì¶”ê°€ ì„¤ì •
        #         request_options={"timeout": 60}  # íƒ€ì„ì•„ì›ƒ ì„¤ì •
        #     )
        #     print("ğŸ”µ ì„ë² ë”© ëª¨ë¸: Gemini")
        # else:
        #     # ê¸°ë³¸ê°’: OpenAI ì„ë² ë”© (GPT ì„ íƒ ì‹œ ì‚¬ìš©, ë” ì•ˆì •ì )
        #     self.embeddings = OpenAIEmbeddings(
        #         model="text-embedding-3-small",
        #         api_key=OPENAI_API_KEY
        #     )
        #     print("ğŸŸ¢ ì„ë² ë”© ëª¨ë¸: OpenAI")

        # self.embeddings = HuggingFaceEmbeddings(
        #     model_name="jhgan/ko-sroberta-multitask",
        #     model_kwargs={'device': 'cpu'},
        #     encode_kwargs={'normalize_embeddings': True}
        # )

        # # DB ì´ˆê¸°í™” (persist_directory=Noneì´ë©´ in-memory ëª¨ë“œ)
        # self.vector_db = Chroma(
        #     persist_directory=self.persist_directory,  # Noneì´ë©´ ë©”ëª¨ë¦¬ë§Œ ì‚¬ìš©
        #     embedding_function=self.embeddings,
        #     collection_name="apt_notices" # ì»¬ë ‰ì…˜ ì´ë¦„ ì§€ì •
        # )

        # gc.collect()

    def add_documents(self, chunks):
        """ì²­í¬ ë¦¬ìŠ¤íŠ¸ë¥¼ ë²¡í„° DBì— ì¶”ê°€ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""
        if not chunks:
            print("âš ï¸ ì €ì¥í•  ì²­í¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ì¤‘ë³µ ë°©ì§€: ë™ì¼ doc_idê°€ ì´ë¯¸ ì €ì¥ë¼ ìˆìœ¼ë©´ ìŠ¤í‚µ
        try:
            first_meta = getattr(chunks[0], "metadata", {}) or {}
            doc_id = str(first_meta.get("doc_id")) if first_meta.get("doc_id") is not None else None
            if doc_id:
                # include ì˜µì…˜ ì—†ì´ í˜¸ì¶œí•˜ë©´ idsëŠ” ê¸°ë³¸ ë°˜í™˜ë¨
                existing = self.vector_db.get(where={"doc_id": doc_id}, limit=1)
                if existing and existing.get("ids"):
                    print(f"â© doc_id={doc_id}ëŠ” ì´ë¯¸ ì €ì¥ë˜ì–´ ìˆì–´ ì¶”ê°€í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                    return
        except Exception as e:
            # ì¤‘ë³µ ì²´í¬ ì‹¤íŒ¨ ì‹œì—ëŠ” ë¡œê·¸ë§Œ ë‚¨ê¸°ê³  ê³„ì† ì§„í–‰
            print(f"âš ï¸ ì¤‘ë³µ í™•ì¸ ì‹¤íŒ¨(ê³„ì† ì§„í–‰): {e}")
        
        print(f"ğŸ’¾ ë²¡í„° DB ì €ì¥ ì‹œì‘... (ì²­í¬ {len(chunks)}ê°œ)")
        
        # ì¬ì‹œë„ ë¡œì§ (429 ì—ëŸ¬ ëŒ€ì‘)
        max_retries = 3
        retry_delay = 2  # ì´ˆê¸° ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
        
        # Render í™˜ê²½ì¸ì§€ í™•ì¸ (ë¡œì»¬ì—ì„œëŠ” í•œ ë²ˆì— ì²˜ë¦¬, Renderì—ì„œëŠ” ë°°ì¹˜ ì²˜ë¦¬)
        is_render = RENDER == "true" or RENDER == "1"
        
        for attempt in range(max_retries):
            try:
                if is_render:
                    # Render í™˜ê²½: ì‘ì€ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬ (rate limit ë°©ì§€)
                    # Gemini API ë¬´ë£Œ í‹°ì–´: ë¶„ë‹¹ ì•½ 15-60 ìš”ì²­ ì œí•œ (ëª¨ë¸ì— ë”°ë¼ ë‹¤ë¦„)
                    batch_size = 5  # í•œ ë²ˆì— ì²˜ë¦¬í•  ì²­í¬ ìˆ˜ (ë” ì‘ê²Œ)
                    for i in range(0, len(chunks), batch_size):
                        batch = chunks[i:i + batch_size]
                        self.vector_db.add_documents(batch)
                        del batch
                        gc.collect()

                        # ë°°ì¹˜ ê°„ ëŒ€ê¸° (rate limit ë°©ì§€) - ë¶„ë‹¹ 15 ìš”ì²­ ê¸°ì¤€ìœ¼ë¡œ ì•½ 4ì´ˆ ê°„ê²©
                        if i + batch_size < len(chunks):
                            wait_time = 4.0  # 4ì´ˆ ëŒ€ê¸° (ë¶„ë‹¹ 15 ìš”ì²­ = 4ì´ˆë‹¹ 1 ìš”ì²­)
                            print(f"  ë°°ì¹˜ {i//batch_size + 1} ì™„ë£Œ. {wait_time}ì´ˆ ëŒ€ê¸° ì¤‘... (rate limit ë°©ì§€)")
                            time.sleep(wait_time)
                else:
                    # ë¡œì»¬ í™˜ê²½: í•œ ë²ˆì— ì²˜ë¦¬
                    self.vector_db.add_documents(chunks)
                
                print("âœ… ë²¡í„° DB ì €ì¥ ì™„ë£Œ!")
                return
                
            except Exception as e:
                error_msg = str(e)
                
                # ì°¨ì› ë¶ˆì¼ì¹˜ ì—ëŸ¬ ì²˜ë¦¬ (ì„ë² ë”© ëª¨ë¸ ë³€ê²½ ì‹œ ë°œìƒ)
                if "dimension" in error_msg.lower() or "expecting embedding" in error_msg.lower():
                    print("âš ï¸ ì„ë² ë”© ì°¨ì› ë¶ˆì¼ì¹˜ ê°ì§€. ê¸°ì¡´ ë²¡í„° DBë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤...")
                    try:
                        # ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ
                        self.vector_db.delete_collection()
                        del self.vector_db
                        gc.collect()
                        # ìƒˆ ì»¬ë ‰ì…˜ ìƒì„± (í˜„ì¬ ì„ë² ë”© ëª¨ë¸ë¡œ)
                        from langchain_chroma import Chroma
                        self.vector_db = Chroma(
                            persist_directory=self.persist_directory,
                            embedding_function=self.embeddings,
                            collection_name="apt_notices"
                        )
                        gc.collect()
                        print("âœ… ë²¡í„° DB ì¬ìƒì„± ì™„ë£Œ. ë‹¤ì‹œ ì‹œë„í•©ë‹ˆë‹¤...")
                        # ì¬ì‹œë„ (í•œ ë²ˆë§Œ)
                        continue
                    except Exception as init_error:
                        print(f"âŒ ë²¡í„° DB ì¬ìƒì„± ì‹¤íŒ¨: {init_error}")
                        raise
                
                # 429 ì—ëŸ¬ ì²˜ë¦¬ (í• ë‹¹ëŸ‰ ì´ˆê³¼)
                elif "429" in error_msg or "RESOURCE_EXHAUSTED" in error_msg or "quota" in error_msg.lower():
                    if attempt < max_retries - 1:
                        # Exponential backoff: ëŒ€ê¸° ì‹œê°„ ì¦ê°€
                        wait_time = retry_delay * (2 ** attempt) + random.uniform(0, 1)
                        print(f"âš ï¸ í• ë‹¹ëŸ‰ ì´ˆê³¼ (429). {wait_time:.1f}ì´ˆ í›„ ì¬ì‹œë„... ({attempt + 1}/{max_retries})")
                        time.sleep(wait_time)
                    else:
                        print(f"âŒ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼. ì—ëŸ¬: {e}")
                        raise
                else:
                    # ë‹¤ë¥¸ ì—ëŸ¬ëŠ” ì¦‰ì‹œ ì¬ë°œìƒ
                    print(f"âŒ ë²¡í„° DB ì €ì¥ ì‹¤íŒ¨: {e}")
                    raise

    def search(self, query, k=3, filter=None):
        """ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰"""
        return self.vector_db.similarity_search(query, k=k, filter=filter)

    def clear(self):
        """ë²¡í„° DB ë°ì´í„°ë¥¼ ëª¨ë‘ ì‚­ì œí•©ë‹ˆë‹¤."""
        try:
            self.vector_db.delete_collection()
            # ì»¬ë ‰ì…˜ ì¬ìƒì„± (ì‚­ì œ í›„ ë‹¤ì‹œ ì“°ê¸° ìœ„í•´)
            del self.vector_db
            gc.collect()

            from langchain_chroma import Chroma
            self.vector_db = Chroma(
                persist_directory=self.persist_directory,  # Noneì´ë©´ in-memory
                embedding_function=self.embeddings,
                collection_name="apt_notices"
            )
            gc.collect()
            print("âœ… ë²¡í„° DB ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
